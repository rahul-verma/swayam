{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_utils import *\n",
    "from swayam import Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Calling with Swayam Tools\n",
    "\n",
    "Let's now start to link the functionality of an LLM Agent with a locally available function call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see what happens without a function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Prompt: (Role: system)\n",
      "--------------------------------------------------------------------------------\n",
      "Prompt: (Role: system)\n",
      "You are a helpful assistant. You are here to help me with my queries.\n",
      "--------------------------------------------------------------------------------\n",
      "Response:\n",
      "Of course! I'm here to help you with any questions or queries you have. What do you need assistance with today?\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Prompt: (Role: user)\n",
      "--------------------------------------------------------------------------------\n",
      "Prompt: (Role: user)\n",
      "What's the weather like in Boston?\n",
      "--------------------------------------------------------------------------------\n",
      "Response:\n",
      "I don't have real-time data access to provide current weather conditions. For the latest weather updates in Boston, I recommend checking a reliable weather website or app.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=\"I don't have real-time data access to provide current weather conditions. For the latest weather updates in Boston, I recommend checking a reliable weather website or app.\", refusal=None, role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from swayam import Swayam\n",
    "Swayam.execute(\"What's the weather like in Boston?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Dummy Functions\n",
    "\n",
    "Let's create some dummy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class UnitEnum(Enum):\n",
    "    CELSIUS = \"celsius\"\n",
    "    FAHRENHEIT = \"fahrenheit\"\n",
    "\n",
    "import json\n",
    "\n",
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "def get_current_weather(location, unit):\n",
    "    import random\n",
    "    i = random.randint(-10, 40)\n",
    "    if unit.lower() == \"celsius\":\n",
    "        return f\"{i}°C\"\n",
    "    elif unit.lower() == \"fahrenheit\":\n",
    "        return f\"{i*9/5 + 32}°F\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid unit\")\n",
    "    \n",
    "def calculate(expression):\n",
    "    return eval(expression)\n",
    "\n",
    "def search_email(text):\n",
    "    import re\n",
    "    emails = re.findall(r'([\\w\\.-]+@[\\w\\.-]+)', text)\n",
    "    if emails:\n",
    "        return emails\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Creation\n",
    "\n",
    "As a part of an LLM workflow, we want to trigger the above local function based on response from the LLM (using function calling).\n",
    "\n",
    "Before we can do that, we need to create a sort of bridge between a function from the view point of an LLM vs what it means in Python.\n",
    "\n",
    "Here we see how we can create convert a function into a Tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToolBuilder\n",
    "\n",
    "We use the tool builder to wrap the function created above.\n",
    "1. Provide the function callable and describe it.\n",
    "2. Add all arguments, while describing their types and purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from swayam.llm.tool import ToolBuilder\n",
    "builder = ToolBuilder(get_current_weather, desc=\"Get the current weather in a given location\")\n",
    "builder.add_field(\"location\", type=str, desc=\"Location to get weather information for\")\n",
    "builder.add_field(\"unit\", type=UnitEnum, desc=\"Unit of temperature\", default=UnitEnum.CELSIUS)\n",
    "get_current_weather_tool = builder.build()\n",
    "\n",
    "builder = ToolBuilder(calculate, desc=\"Evaluates a mathematical expression\")\n",
    "builder.add_field(\"expression\", type=str, desc=\"The expression to be evaluated.\")\n",
    "calc_tool = builder.build()\n",
    "\n",
    "builder = ToolBuilder(search_email, desc=\"Searches email addresses in a given text\")\n",
    "builder.add_field(\"text\", type=str, desc=\"The target text in which emails are to be searched.\")\n",
    "search_email_tool = builder.build()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool Execution\n",
    "\n",
    "The key thing to keep in mind is that all arguments are passed as keyword arguments irrespective of the underlying function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'40°C'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_weather_tool(location=\"dummy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2°C'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_weather_tool(**{\"location\": \"dummy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'73.4°F'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_weather_tool(**{\"location\": \"dummy\", \"unit\":\"fahrenheit\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_tool(expression=\"2 + 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a@b.com']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_email_tool(text=\"This is a sample text with a@b.com address\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_email_tool(text=\"This is a sample text with no email address\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool Definition\n",
    "\n",
    "One of the key benefits of creating a Tool is that it self describes itself, in a way compatible with an LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'function', 'function': {'name': 'get_current_weather', 'description': 'Get the current weather in a given location', 'parameters': {'properties': {'location': {'description': 'Location to get weather information for', 'title': 'Location', 'type': 'string'}, 'unit': {'description': 'Unit of temperature', 'enum': ['celsius', 'fahrenheit'], 'type': 'string'}}, 'required': ['location'], 'type': 'object'}}}\n"
     ]
    }
   ],
   "source": [
    "print(get_current_weather_tool.definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'function', 'function': {'name': 'calculate', 'description': 'Evaluates a mathematical expression', 'parameters': {'properties': {'expression': {'description': 'The expression to be evaluated.', 'title': 'Expression', 'type': 'string'}}, 'required': ['expression'], 'type': 'object'}}}\n"
     ]
    }
   ],
   "source": [
    "print(calc_tool.definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'function', 'function': {'name': 'search_email', 'description': 'Searches email addresses in a given text', 'parameters': {'properties': {'text': {'description': 'The target text in which emails are to be searched.', 'title': 'Text', 'type': 'string'}}, 'required': ['text'], 'type': 'object'}}}\n"
     ]
    }
   ],
   "source": [
    "print(search_email_tool.definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the list of tool definitions to be shared with the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_current_weather_tool, calc_tool, search_email_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a tools dictionary so that once we know the name of the tool from LLM, we can call it with arguments returned from the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HtmlReporter' object has no attribute '_HtmlReporter__json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mswayam\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Agent, Prompt\n\u001b[1;32m      3\u001b[0m prompt \u001b[38;5;241m=\u001b[39m Prompt\u001b[38;5;241m.\u001b[39mas_system(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a useful assistant. You are provided with a list of tools to help users with their queries.\u001b[39m\u001b[38;5;124m\"\u001b[39m, tools\u001b[38;5;241m=\u001b[39mtools)\n\u001b[0;32m----> 4\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43mAgent\u001b[49m\u001b[43m(\u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m agent \u001b[38;5;241m=\u001b[39m Agent(display\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/GitHub/swayam/swayam/llm/agent.py:61\u001b[0m, in \u001b[0;36mAgent.__init__\u001b[0;34m(self, name, provider, model, temperature, system_prompt, display, report_html, show_in_browser, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__system_prompt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__system_prompt \u001b[38;5;241m=\u001b[39m SystemPrompt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpful assistant. You are here to help me with my queries.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__system_prompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/swayam/swayam/llm/agent.py:111\u001b[0m, in \u001b[0;36mAgent.execute\u001b[0;34m(self, same_context, response_format, functions, *nodes)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexecutor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConversationExecutor\n\u001b[1;32m    110\u001b[0m executor \u001b[38;5;241m=\u001b[39m ConversationExecutor(model_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__model_config, prompt_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__prompt_config, listener\u001b[38;5;241m=\u001b[39mlistener)\n\u001b[0;32m--> 111\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconversation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconversation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunctions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m output_list\u001b[38;5;241m.\u001b[39mextend(output)\n\u001b[1;32m    113\u001b[0m log_debug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished PromptNode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/swayam/swayam/llm/executor.py:77\u001b[0m, in \u001b[0;36mConversationExecutor.execute\u001b[0;34m(self, conversation, response_format, functions)\u001b[0m\n\u001b[1;32m     75\u001b[0m     output_messages\u001b[38;5;241m.\u001b[39mappend(output_message)\n\u001b[1;32m     76\u001b[0m     response_message \u001b[38;5;241m=\u001b[39m LLMResponse\u001b[38;5;241m.\u001b[39mcreate_response_object(output_message)\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreport_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_message\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     conversation\u001b[38;5;241m.\u001b[39mcontext\u001b[38;5;241m.\u001b[39mappend_assistant_response(response_message\u001b[38;5;241m.\u001b[39mas_dict())\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output_messages\n",
      "File \u001b[0;32m~/Documents/GitHub/swayam/swayam/llm/listener.py:71\u001b[0m, in \u001b[0;36mAgentListener.report_response\u001b[0;34m(self, prompt, message)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03mBroadcasts the output message.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m    message (dict): Response dict from LLM.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m reporter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reporters:\n\u001b[0;32m---> 71\u001b[0m     \u001b[43mreporter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreport_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/swayam/swayam/llm/report.py:388\u001b[0m, in \u001b[0;36mHtmlReporter.report_response\u001b[0;34m(self, prompt, response)\u001b[0m\n\u001b[1;32m    377\u001b[0m     children\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m    378\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__response_counter),\n\u001b[1;32m    379\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeeds Function Call\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    383\u001b[0m                     }\n\u001b[1;32m    384\u001b[0m                 })\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompt\u001b[38;5;241m.\u001b[39mrole \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 388\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__json\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchildren\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchildren\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mextend(children)\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_latest_conversation_node()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchildren\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mextend(children)       \n",
      "\u001b[0;31mAttributeError\u001b[0m: 'HtmlReporter' object has no attribute '_HtmlReporter__json'"
     ]
    }
   ],
   "source": [
    "from swayam import Agent, Prompt\n",
    "\n",
    "prompt = Prompt.as_system(\"You are a useful assistant. You are provided with a list of tools to help users with their queries.\", tools=tools)\n",
    "agent = Agent(system_prompt=prompt)\n",
    "agent = Agent(display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from swayam import Prompt\n",
    "prompt = Prompt.as_user(\"What's the weather like in Boston?\", tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_json = agent.execute(\"What's the weather like in Boston?\", functions=functions).function_call\n",
    "tools[function_json.name](**json.loads(function_json.arguments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_json = agent.execute(\"What is 7 *30 + 13?\", functions=functions).function_call\n",
    "tools[function_json.name](**json.loads(function_json.arguments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is a sample text with a@b.com and c@d.com addresses\"\n",
    "function_json = agent.execute(f\"Find whether there is an email address in the following text marked with triple backticks \\n ```{text}```?\", functions=functions).function_call\n",
    "tools[function_json.name](**json.loads(function_json.arguments))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3108",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
